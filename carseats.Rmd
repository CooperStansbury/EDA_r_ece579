---
title: "Carseats R Notebook"
output:
  html_document
---
# Introduction
Here is my analysis of `data/Carseats_org.csv`.

## Configuration

```{r, message=FALSE}
library(leaps)
library(data.table)
library(stringr)
library(caret)
library(ggplot2)
library(DataExplorer)
library(dplyr)
library(ggExtra)
library(RColorBrewer)
library(plotly)
library(corrplot)
library(htmltools)
library(MASS)
library(GPArotation)
library(psych)
library(mgcv)
library(tidyverse)
library(mltools)
```

## System Information
Due to the large number of libraries in use I have provided system information.

```{r}
sessionInfo()
sapply(c('repr', 'IRdisplay', 'IRkernel'), function(p) paste(packageVersion(p)))
```

# Data
I load the data into `r`, and drop the "ID" column.

```{r}
carseats <- read.csv("data/Carseats_org.csv", header = T, stringsAsFactors = T)

drops <- c("X")
carseats <- carseats[ , !(names(carseats) %in% drops)]
head(carseats, 10)
```

Here I create two new data frames to manage numeric and categorical data.

```{r}
# get vectors of continuous and categorical cols
nums <- dplyr::select_if(carseats, is.numeric)
cats <- dplyr::select_if(carseats, is.factor)

nums[sample(nrow(nums), 10), ]

cats[sample(nrow(cats), 10), ]
```

## Numeric Summaries

```{r}
summary(nums)
```

```{r}
str(nums)
```

## Categorical Summaries

```{r}
summary(cats)
```

```{r}
str(cats)
```


# Data Dimensionality
This command is to inspect the different data types in the data.

```{r}
str(carseats)
```

```{r}
print(paste('Number of Columns:', ncol(carseats)))
print(paste('Number of Numeric Columns:', ncol(nums)))
print(paste('Number of Categorical Columns:', ncol(cats)))
```


```{r}
dim(carseats)
dim(nums)
dim(cats)
```


Here's a quick way to examine general properties of the data:

```{r}
DataExplorer::introduce(data=carseats)
```

Finally, I want to look at the first and last rows of the data set. Just to be safe:

```{r}
head(carseats, 2)
tail(carseats, 2)

head(nums, 2)
tail(nums, 2)

head(cats, 2)
tail(cats, 2)
```

# Numeric Plotting
I start out with a few general scatter plots.

```{r, message=FALSE}
plot_ly(data=carseats,
        x=~Age,
        y=~Sales,
        mode = 'markers',
        type = 'scatter',
        color=~ShelveLoc) %>%
            layout(title = "Age, Shelf Location, and Sales Scatter Plot", width=900)
```

This plot below shows good separation and a weak linear trend. These variables are worth investigating.

```{r, message=FALSE}
plot_ly(data=carseats,
        x=~Price,
        y=~Sales,
        mode = 'markers',
        type = 'scatter',
        color=~ShelveLoc) %>%
            layout(title = "Price, Shelf Location, and Sales Scatter Plot", width=900)
```

Here we inspect the density of the 'Price vs Sales' relationship:

```{r, message=FALSE}
plot_ly(data=carseats,
        x=~Price,
        y=~Sales,
        mode = 'markers',
        size = ~Price,
        type = 'scatter',
        colors = "Dark2",
        alpha = .6) %>%
            layout(title = "Price, US, and Sales Scatter Plot", width=900)
```

# Normalization
I choose to normalize the numeric data in order to be able to plot each variable on the same scale. This will allow me to investigate the variation of each predictor relative to Sales.

```{r}
preObj <- preProcess(nums, method=c("center", "scale"))
scaled.nums <- predict(preObj, nums)

head(scaled.nums, 2)
tail(scaled.nums, 2)
```

```{r}
str(scaled.nums)
print("")
summary(scaled.nums)
```

## Distributions
Here are scaled distributions (histograms and density plots) for each numeric variable, including Sales. The variables relating to money ($) tend to be approximately normal. Many other variables tend to be approximately uniform, which does not bode well for their predictive power.

```{r, message=FALSE}
scaled.nums %>%
    tidyr::gather() %>%
        ggplot(aes(x=value,y=..density..))+

            ggtitle('Distributions of Continous Variables (scaled)') +

            facet_wrap(~ key, scales = "free") +
            geom_histogram(fill=I("orange"), col=I("black"), bins = 50) +

            facet_wrap(~ key, scales = "free") +
            geom_density(color="blue", fill='light blue', alpha = 0.4)
```

Here we plot all numeric variables against their distributions. This is just another way to examine the information shown above.

```{r, message=FALSE}
scaled.nums %>%
    tidyr::gather() %>%
        plot_ly(x=~key, y=~value,
                type = "box",
                boxpoints = "all",
                jitter = 0.4,
                pointpos = 0,
                color = ~key,
                colors = "Dark2") %>%
                      subplot(shareX = TRUE)  %>%
                            layout(title = "Numeric Variable Distributions (scaled)",
                                  yaxis=list(title='Standard Deviation'),
                                  xaxis=list(title='Variable'),
                                  autosize=FALSE,
                                  width=900,
                                  height=500)
```

## Scatterplots

Here we plot all numeric variables against Sales (scaled). This allows us to investigate possible linear relationships between that variable and Sales. As shown below, only 'Price' appears to have a linear relationship worth investigating. This took me so long to figure out.

```{r, message=FALSE}

numeric.scatterplots <- htmltools::tagList()
count = 1

for (i in names(scaled.nums[,-1])) {

  numeric.scatterplots[[count]] <- plot_ly(scaled.nums, x=scaled.nums[,i], y=scaled.nums$Sales,
                    colors = 'RdYlGn',
                    mode = 'markers',
                    type = 'scatter',
                    size = scaled.nums$Sales^2,
                    color = scaled.nums$Sales,
                    marker = list(line = list(color = 'black',width = 2)),
                    name=paste(i)) %>%
          layout(title = paste(i, "vs Sales (scaled)<br>Size=Sales^2"),
                               yaxis=list(title='Sales'),
                               xaxis=list(title=i),
                               showlegend = FALSE)

  count = count + 1

}

numeric.scatterplots

```

By adding naive regression lines to a few scatter plots we can confirm our suspicions:

```{r, message=FALSE}
fit.Pop <- lm(Sales ~ Population, data = scaled.nums)
fit.Age <- lm(Sales ~ Age, data = scaled.nums)
fit.CompPrice <- lm(Sales ~ CompPrice, data = scaled.nums)
fit.Price <- lm(Sales ~ Price, data = scaled.nums)

regression.scatterplots <- htmltools::tagList()

regression.scatterplots[[1]] <-  plot_ly(scaled.nums,
          x = ~Population,
          name = 'Population vs Sales Regression Line') %>%
              add_markers(y = ~Sales,
                    name = 'Population vs Sales Observations') %>%
                            add_lines(x = ~Population,
                                  y = fitted(fit.Pop)) %>%
                                        layout(title = "Population vs Sales",
                                               yaxis=list(title='Sales',
                                               xaxis=list(title='Population')),
                                               showlegend = FALSE)



regression.scatterplots[[2]] <-  plot_ly(scaled.nums,
          x = ~Age,
          name = 'Age vs Sales Regression Line') %>%
              add_markers(y = ~Sales,
                    name = 'Age vs Sales Observations') %>%
                            add_lines(x = ~Age,
                                  y = fitted(fit.Age)) %>%
                                        layout(title = "Age vs Sales",
                                               yaxis=list(title='Sales',
                                               xaxis=list(title='Age')),
                                               showlegend = FALSE)

regression.scatterplots[[3]] <-  plot_ly(scaled.nums,
          x = ~CompPrice,
          name = 'CompPrice vs Sales Regression Line') %>%
              add_markers(y = ~Sales,
                    name = 'CompPrice vs Sales Observations') %>%
                            add_lines(x = ~CompPrice,
                                  y = fitted(fit.CompPrice)) %>%
                                        layout(title = "CompPrice vs Sales",
                                               yaxis=list(title='Sales',
                                               xaxis=list(title='CompPrice')),
                                               showlegend = FALSE)

regression.scatterplots[[4]] <-  plot_ly(scaled.nums,
          x = ~Price,
          name = 'Price vs Sales Regression Line') %>%
              add_markers(y = ~Sales,
                    name = 'Price vs Sales Observations') %>%
                            add_lines(x = ~Price,
                                  y = fitted(fit.Price)) %>%
                                        layout(title = "Price vs Sales",
                                               yaxis=list(title='Sales',
                                               xaxis=list(title='Price')),
                                               showlegend = FALSE)


regression.scatterplots
```

Let's compare the slopes:

```{r, message=FALSE}
scaled.nums %>%
    plot_ly(y = ~Sales) %>%
      add_lines(x= ~Population, y = fitted(fit.Pop),
                name = "fit.Pop slope", line = list(shape = "linear")) %>%
      add_lines(x= ~Age, y = fitted(fit.Age),
                name = "fit.Age slope", line = list(shape = "linear")) %>%
      add_lines(x= ~CompPrice, y = fitted(fit.CompPrice),
                name = "fit.CompPrice slope", line = list(shape = "linear")) %>%
      add_lines(x= ~Price, y = fitted(fit.Price),
                name = "fit.Price slope", line = list(shape = "linear")) %>%

    layout(title = "Regression Lines vs Sales (scaled)",
           autosize=FALSE,
           width=900,
           yaxis=list(title='Sales'),
           xaxis=list(title='Scaled Numeric Variable'))
```

Here's a pretty graphic that doesn't help me understand anything about the data.

```{r, message=FALSE}
y = scaled.nums$Sales
x = scaled.nums$Price

s <- subplot(
  plot_ly(x = x, color = I("black"), type = 'histogram'),
  plotly_empty(),
  plot_ly(x = x, y = y, type = 'histogram2dcontour', showscale = F),
  plot_ly(y = y, color = I("black"), type = 'histogram'),
  nrows = 2, heights = c(0.2, 0.8), widths = c(0.8, 0.2),
  shareX = TRUE, shareY = TRUE, titleX = FALSE, titleY = FALSE)

layout(s, showlegend = FALSE, autosize=FALSE,
           width=700,
           height=500,
           yaxis=list(title='Sales'),
           xaxis=list(title='Price'))
```

# Categorical Plotting
First, let's create a data frame that we can use:
```{r, message=FALSE}
categorical.by.sales = cbind(Sales = scaled.nums$Sales, cats)
str(categorical.by.sales)
```

Here we can see all categorical by Sales. We suspected that 'ShelveLoc' would be important based on one of the early scatter plots. It seems that this is the case.

```{r, message=FALSE}

categorical.boxplots <- htmltools::tagList()
count = 1

for (i in names(categorical.by.sales[,-1])) {

  categorical.boxplots[[count]] <- plot_ly(categorical.by.sales, x=categorical.by.sales[,i], y=categorical.by.sales$Sales,
                        type = "box",
                        boxpoints = "all",
                        jitter = .2,
                        pointpos = 0,
                        color =categorical.by.sales[,i],
                        colors='Set1',
                        name=paste(i)) %>%
                            layout(title = paste(i, "vs Sales (scaled)"),
                                  showlegend = TRUE,
                                  yaxis=list(title='Sales Standard Deviation'),
                                  xaxis=list(title=i))

  count = count + 1

}

categorical.boxplots
```

Here's the same thing, but more musically:

```{r, message=FALSE}

categorical.violins <- htmltools::tagList()
count = 1

for (i in names(categorical.by.sales[,-1])) {

  categorical.violins[[count]] <- plot_ly(categorical.by.sales, x=categorical.by.sales[,i], y=categorical.by.sales$Sales,
                        split = categorical.by.sales[,i],
                        type = 'violin',
                        colors='Set1',
                        name=paste(i),
                        box = list(visible = TRUE),
                        meanline = list(visible = TRUE)) %>%
                            layout(xaxis = list(title = "US"),
                                yaxis = list(title = "Sales",zeroline = FALSE))


  count = count + 1

}

categorical.violins
```

# Linear Regression

First, let's merge the data set into a single data frame
```{r}

scaled.merged <- cbind(categorical.by.sales[,-1], scaled.nums)
str(scaled.merged)
```

```{r}
head(nums, 2)
tail(nums, 2)

head(scaled.merged, 2)
tail(scaled.merged, 2)
```


First, let's look at some things that may give us trouble. Luckily it looks like the only serious correlation is with our dependent variable. We'll want to watch the 'Price' vs 'CompPrice' relationship.

```{r, message=FALSE}
res <- cor(scaled.nums)

corrplot(res, type = "upper", order = "hclust",
         tl.col = "black", tl.srt = 45)
```

It appears that residuals are roughly symmetrical around 0. That's strange. Mostly due to a relatively poor overall fit. Note how close to zero most of the coefficient estimates are.

```{r}
simple.lm <- lm(Sales~., data=scaled.merged)
simple.summary <- summary(simple.lm)

print(simple.summary)
```

## Linear Models and Subsets

Let's do the same thing, but control the subsets using `leaps`

```{r}
regfit.full=regsubsets(Sales~., data=scaled.merged, nvmax=5)
reg.summary=summary(regfit.full)

print(reg.summary)
```

We'll just take code straight from the example on Canvas...

```{r}
par(mfrow=c(2,2))
plot(reg.summary$rss,xlab="Number of Variables",ylab="RSS",type="l")
plot(reg.summary$adjr2,xlab="Number of Variables",ylab="Adjusted RSq",type="l")
plot(reg.summary$cp,xlab="Number of Variables",ylab="Cp",type='l')
plot(reg.summary$bic,xlab="Number of Variables",ylab="BIC",type='l')
```

```{r}
plot(regfit.full,scale="r2")
plot(regfit.full,scale="adjr2")
plot(regfit.full,scale="Cp")
plot(regfit.full,scale="bic")
```


# Interaction Terms

Here we define a new model with some interaction terms:
    a.  Income and Advertising
    b.  Income and CompPrice
    c.   Price and Age


```{r}
interaction.lm <- lm(Sales~. + Income*Advertising + Income*CompPrice + Price*Age, data=scaled.merged)
interaction.summary <- summary(interaction.lm)

print(interaction.summary)
```

```{r}
interaction.lm.subsets <- regsubsets(Sales~. + Income*Advertising + Income*CompPrice + Price*Age,
                                     data=scaled.merged, nvmax=5)

interaction.subsets.summary <- summary(interaction.lm.subsets)

print(interaction.subsets.summary)
```


## Variable Significance
Below we print the coefficients for the 5th model using the default model selection criteria. All coefficients are relatively small, as we would expect from the EDA above. This pretty much confirms what I would have guessed by looking at the data against sales. We still want to watch out for confounding between 'Price' and 'CompPrice.'


```{r}
coef(interaction.lm.subsets, 5)
```

## Second Interaction Model

First, drop columns unneeded from analysis:

```{r}
scaled.merged.slim <- scaled.merged[ , -which(names(scaled.merged) %in% c("US","Urban"))]
```


A few hyper parameters we'd like to be consistent for all models

```{r}
nvmax <- 3
```

## Forward Selection:

```{r}
interaction.subset.fwd <- regsubsets(Sales~. + Income*Advertising + Income*CompPrice + Income*Age,
                                     data=scaled.merged.slim,
                                     nvmax = nvmax,
                                     method="forward")

fwd.subset.summary <- summary(interaction.subset.fwd)

coef(interaction.subset.fwd, 1:nvmax)
```

## Backward Selection:

This is really strange. I can't seem to find any documentation about this, but it appears that this model is actually 'forward.'

```{r}
interaction.subset.bk <- regsubsets(Sales~. + Income*Advertising + Income*CompPrice + Income*Age,
                                     data=scaled.merged.slim,
                                     nvmax = nvmax,
                                     method="backward")

bk.subset.summary <- summary(interaction.subset.bk)

coef(interaction.subset.bk, 1:nvmax)
```

## Exhaustive

```{r}
interaction.subset.ex <- regsubsets(Sales~. + Income*Advertising + Income*CompPrice + Income*Age,
                                     data=scaled.merged.slim,
                                     nvmax = nvmax,
                                     method="exhaustive")

ex.subset.summary <- summary(interaction.subset.ex)
coef(interaction.subset.ex, 1:nvmax)
```

This is a list that may come in handy.

```{r}
model.list = list(list("Forward", interaction.subset.fwd, fwd.subset.summary),
                  list("Backward", interaction.subset.bk, bk.subset.summary),
                  list("Exhaustive", interaction.subset.ex, ex.subset.summary))
```

# Evaluation Metric Plotting

It is interesting to see that each model selected the same variables, in the same order.

```{r}
par(mfrow=c(2,2))
plot(fwd.subset.summary$rss,xlab="Number of Variables (forward)",ylab="RSS",type="l")
plot(fwd.subset.summary$adjr2,xlab="Number of Variables (forward)",ylab="Adjusted RSq",type="l")
plot(fwd.subset.summary$cp,xlab="Number of Variables (forward)",ylab="Cp",type='l')
plot(fwd.subset.summary$bic,xlab="Number of Variables (forward)",ylab="BIC",type='l')
```

```{r}
par(mfrow=c(2,2))
plot(bk.subset.summary$rss,xlab="Number of Variables (backward)",ylab="RSS",type="l")
plot(bk.subset.summary$adjr2,xlab="Number of Variables (backward)",ylab="Adjusted RSq",type="l")
plot(bk.subset.summary$cp,xlab="Number of Variables (backward)",ylab="Cp",type='l')
plot(bk.subset.summary$bic,xlab="Number of Variables (backward)",ylab="BIC",type='l')
```

```{r}
par(mfrow=c(2,2))
plot(ex.subset.summary$rss,xlab="Number of Variables (exhaustive)",ylab="RSS",type="l")
plot(ex.subset.summary$adjr2,xlab="Number of Variables (exhaustive)",ylab="Adjusted RSq",type="l")
plot(ex.subset.summary$cp,xlab="Number of Variables (exhaustive)",ylab="Cp",type='l')
plot(ex.subset.summary$bic,xlab="Number of Variables (exhaustive)",ylab="BIC",type='l')
```

# Model Equations

Here we print the final equations for each model. Not, they are all the same.

```{r}

for (mod.obj in model.list) {
  mod.name <- mod.obj[[1]]
  best.bic <- min(mod.obj[[3]]$bic)
  mod.num <- which.min(mod.obj[[3]]$bic)
  mod.cc <- coef(mod.obj[[2]], mod.num)

  mod.equation.format <- paste("Y =", paste(round(mod.cc[1],2),
                      paste(round(mod.cc[-1],2),
                      names(mod.cc[-1]),
                      sep=" * ", collapse=" + "),
                      sep=" + "), "+ e")

  print(paste("Model Selection Method: ",mod.name))
  print(paste("Min BIC:", best.bic))
  print(paste("Model Number: ", mod.num))
  print(paste("Model Equation: ", mod.equation.format))
  print("")

}
```

Formally, we are looking for:
$$\hat{Y} = \beta_0 + \beta_1X_1 + \beta_2X_2 + \beta_3X_3 + \epsilon$$
Our model yields:
$$\hat{Y} = -0.27 + 1.27(ShelveLocGood) + 0.49(CompPrice) + -0.76(Price)$$

# Appendix A: PCA
This is what I would try (though, I think there is enough evidence to suggest that this data is synthetic.) PCA doesn't help us very much, but we'll see...

```{r}
scaled.nums <- dplyr::select_if(scaled.merged, is.numeric)
scaled.nums <- scaled.nums[,-1]
```


```{r}
pc_result = principal(scaled.nums, nfactors = 3)
print(pc_result$Vaccounted)
print(pc_result$weights)
```


```{r}
fa.diagram(pc_result)
```
```{r}
biplot(pc_result)
```

```{r}
pca.df <- cbind(pc_result$scores, scaled.merged[1:4])
pca.df.h1 <- one_hot(as.data.table(pca.df))
head(pca.df.h1)

```

Empirically I tried a GAM model and a SVM. These weren't impressive enough out of the box to show here. On to the next task...
